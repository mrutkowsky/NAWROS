DIRECTORIES:
  data: data
  stop_words: stop_words
  cleared_files: cleared_files
  valid_files: validated_files
  raports: raports
  empty_content: empty_content
  tmp: tmp
  embeddings: embeddings
  faiss_vectors: faiss_vectors
  current_df: current_df
  filtered_df: filtered_df
  swearwords_dir: swear_words

FILES:
  embedded_files: embeddings.json
  current_df: current_df.gzip.parquet
  current_df: current_df.parquet.gzip
  filtered_df: filtered_df.parquet.gzip
  polish_swearwords: 'polish_swearwords.txt'
  english_swearwords: 'english_swearwords.txt'
  filtered_df: filtered_df.csv

INPUT_FILES_SETTINGS:
  allowed_extensions:
    - .csv 
    - .txt'
    - .xlsx
  required_columns: 
    - Questioned_Date
    - Model_No
    - OS
    - SW_Version 
    - CSC
    - Category 
    - Application_Name
    - content

RAPORT:
  columns:
    - Questioned_Date
    - Model_No
    - OS
    - SW_Version 
    - CSC
    - Category 
    - Application_Name
    - content 
    - labels

LOGGER:
  logging_format: '%(asctime)s - %(levelname)s - %(message)s'
  logger_level: INFO

EMPTY_CONTENT_SETTINGS:
  empty_content_suffix: _EMPTY_CONTENT
  empty_content_ext: .csv

PIPELINE:
  content_column: content
  batch_size: 32
  cleared_file_ext: .csv

ML:
  seed: 42
  embeddings:
    model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
  UMAP:
    n_neighbors: 15
    min_dist: 0.0
    n_components: 5
  topics:
    - 2
  sentiment:
    model_name: 'cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual'
    
  HDBSCAN:
    min_cluster_size: 15
    min_samples: 15
    metric: euclidean                      
    cluster_selection_method: eom
 
  sentiment:
    model_name: 'cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual'

FILTERING:
  download_name: 'filtered_data.xlsx'
